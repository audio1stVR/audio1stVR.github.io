<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>NIME Workshop on Audio-first VR</title>
  <link rel="stylesheet" type="text/css" href="style.css">

</head>

<body>
  <div id="title">NIME Workshop on Audio-first VR</div>
  <div id="bio-container">
    <div class="bio">
      <p>We are rapidly approaching the mass adoption of virtual reality as a
      consumer-oriented entertainment medium. Recent breakthroughs in
      low-persistence monitors combined with modern head-tracking techniques
      have enabled the design of head-mounted displays that offer plausible
      virtual experiences. The role of sound in establishing a convincing sense
      of immersion in such experiences has been acknowledged since the early
      days of VR. Morton Heilig’s 1960 patent for a stereoscopic television
      apparatus, which is one of the earliest concept designs for a VR system,
      describes the use of ear phones and binaural sound. Ivan Sutherland, the
      designer of what is considered to be the first head-mounted display, wrote
      in 1965 that despite the availability of excellent audio output devices,
      the computers had not yet been capable of producing meaningful sounds that
      can be integrated into “the ultimate display.” Since then, significant
      advances in digital computing has facilitated the development of real-time
      audio synthesis and spatialization techniques. Modern consumer-grade
      computers are capable of executing complex sound-field synthesis
      algorithms that are suitable for VR applications.</p>

      <p>Leading technology companies today are growingly invested in spatial audio
      with new products, such as Facebook’s Spatial Workstation and Google’s
      Resonance Audio, that facilitate the use of Ambisonics and binaural audio
      with popular VR platforms. However, most modern VR systems impart an
      ancillary role to audio, where sounds serve to amplify visual immersion.
      It is up to sound and music researchers to elaborate ways in which we can
      think natively about VR audio. This workshop aims to investigate the
      concept of an audio-centric VR as a medium for musical expression, and
      identify multimodal experiences that focus on the auditory aspects of
      immersion rather than those that are ocular. Through a day-long workshop
      that involves presentations and demo sessions followed by round table
      discussions, the participants will collectively address such questions as:
      What is a VR experience that originates from sonic phenomena? How do we
      behave and interact inside such experiences? What are the tools that we
      have or need to create these experiences? What are the implications of an
      audio-centric VR for musical expression?</p>

      <p>We seek abstract submissions that focus on the following topics among others:
        <li>Sonic virtual realities
        <li>Immersive sonification
        <li>Virtual interfaces for musical expression (VIMEs)
        <li>Creativity support tools for VR audio
        <li>Visualizing an audio-centric VR
        <li>Spatial audio systems for VR
        <li>Embodied interactions within virtual audio systems
        <li>Applications of computer music theory to VR
        <li>Sonic VR as assistive technology
        <li>Histories of Sound in Virtual Environments

      <p>Workshop structure:
        <li>9:00-12:00 – 15-minute presentations by the participants
        <li>12:00-13:00 – Lunch break
        <li>13:00-14:00 – Demo session (a room-scale VR system and a 4-channel audio system will be provided)
        <li>14:00-17:00 – Discussion, elaborating the outline of a position

    </div>
  </div>
</body>

</html>
